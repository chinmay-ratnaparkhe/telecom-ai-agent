{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8893a34d",
   "metadata": {},
   "source": [
    "# Telecom AI Platform v2.0 - Complete Guide\n",
    "\n",
    "###  This Notebook Covers:\n",
    "\n",
    "1. Platform Architecture Overview\n",
    "2. Data Processing Pipeline\n",
    "3. Anomaly Detection Models\n",
    "4. Conversational AI Agent\n",
    "5. API Server Usage\n",
    "6. Visualization Capabilities\n",
    "7. Complete Workflow Examples\n",
    "8. Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a028d16",
   "metadata": {},
   "source": [
    "## 1. Platform Architecture Overview\n",
    "\n",
    "The refactored platform follows a clean, modular architecture:\n",
    "\n",
    "```\n",
    "telecom_ai_platform/\n",
    "├── core/                   # Core functionality\n",
    "│   ├── config.py          # Configuration management\n",
    "│   └── data_processor.py  # Data processing pipeline\n",
    "├── models/                 # Machine learning models\n",
    "│   ├── anomaly_detector.py # Anomaly detection models\n",
    "│   └── trainer.py         # Model training pipeline\n",
    "├── agents/                 # AI agents\n",
    "│   └── conversational_ai.py # Conversational AI agent\n",
    "├── server/                 # Web API server\n",
    "│   └── api.py             # FastAPI application\n",
    "├── utils/                  # Utilities\n",
    "│   ├── logger.py          # Logging utilities\n",
    "│   └── visualizer.py      # Visualization tools\n",
    "└── main.py                # Entry point\n",
    "```\n",
    "\n",
    "### Key Design Principles:\n",
    "\n",
    "- **Separation of Concerns**: Each module has a specific responsibility\n",
    "- **Dependency Injection**: Configuration passed to components\n",
    "- **Factory Pattern**: Easy component instantiation\n",
    "- **Logging Integration**: Consistent logging across all components\n",
    "- **Error Handling**: Robust error handling and recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445912a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\n",
      "Current working directory: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\notebooks\n",
      "Platform components imported successfully!\n",
      "Available modules:\n",
      "   • Configuration Management\n",
      "   • Data Processing Pipeline\n",
      "   • Anomaly Detection Models\n",
      "   • Conversational AI Agent\n",
      "   • Visualization Tools\n",
      "   • Complete Platform Interface\n",
      "Platform components imported successfully!\n",
      "Available modules:\n",
      "   • Configuration Management\n",
      "   • Data Processing Pipeline\n",
      "   • Anomaly Detection Models\n",
      "   • Conversational AI Agent\n",
      "   • Visualization Tools\n",
      "   • Complete Platform Interface\n"
     ]
    }
   ],
   "source": [
    "# Let's start by importing the main platform components\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the platform to Python path - correct the path\n",
    "# The notebook is in telecom_ai_platform/notebooks/, so we need to go up two levels to reach the workspace root\n",
    "workspace_root = Path(__file__).parent.parent.parent if '__file__' in globals() else Path('.').parent.parent\n",
    "sys.path.insert(0, str(workspace_root))\n",
    "\n",
    "# Alternative approach - add the parent directory of telecom_ai_platform to path\n",
    "platform_parent = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if platform_parent not in sys.path:\n",
    "    sys.path.insert(0, platform_parent)\n",
    "\n",
    "print(f\"Added to Python path: {platform_parent}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Import platform components\n",
    "try:\n",
    "    from telecom_ai_platform.core.config import TelecomConfig\n",
    "    from telecom_ai_platform.core.data_processor import TelecomDataProcessor\n",
    "    from telecom_ai_platform.models.anomaly_detector import KPIAnomalyDetector\n",
    "    from telecom_ai_platform.models.trainer import ModelTrainer\n",
    "    from telecom_ai_platform.agents.conversational_ai import TelecomConversationalAgent\n",
    "    from telecom_ai_platform.utils.visualizer import TelecomVisualizer\n",
    "    from telecom_ai_platform.main import TelecomAIPlatform\n",
    "\n",
    "    print(\"Platform components imported successfully!\")\n",
    "    print(\"Available modules:\")\n",
    "    print(\"   • Configuration Management\")\n",
    "    print(\"   • Data Processing Pipeline\") \n",
    "    print(\"   • Anomaly Detection Models\")\n",
    "    print(\"   • Conversational AI Agent\")\n",
    "    print(\"   • Visualization Tools\")\n",
    "    print(\"   • Complete Platform Interface\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Checking available modules...\")\n",
    "    \n",
    "    # Check what's actually available\n",
    "    telecom_platform_path = os.path.join(platform_parent, 'telecom_ai_platform')\n",
    "    if os.path.exists(telecom_platform_path):\n",
    "        print(f\"telecom_ai_platform directory found at: {telecom_platform_path}\")\n",
    "        print(\"Contents:\")\n",
    "        for item in os.listdir(telecom_platform_path):\n",
    "            print(f\"   • {item}\")\n",
    "    else:\n",
    "        print(f\"telecom_ai_platform directory not found at: {telecom_platform_path}\")\n",
    "        print(\"Available directories:\")\n",
    "        for item in os.listdir(platform_parent):\n",
    "            if os.path.isdir(os.path.join(platform_parent, item)):\n",
    "                print(f\"   • {item}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2925d6",
   "metadata": {},
   "source": [
    "## 2. Configuration Management\n",
    "\n",
    "The platform uses a centralized configuration system that makes it easy to customize behavior without changing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6294580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Details:\n",
      "   Data Directory: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\data\n",
      "   Models Directory: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\n",
      "   Logs Directory: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\logs\n",
      "   KPI Columns: ['RSRP', 'SINR', 'DL_Throughput', 'UL_Throughput', 'CPU_Utilization', 'Active_Users', 'RTT', 'Packet_Loss', 'Call_Drop_Rate', 'Handover_Success_Rate']\n",
      "   Contamination Rate: 0.05\n",
      "   AI Model: gemini-1.5-flash\n",
      "   Temperature: 0.7\n",
      "   Debug Mode: False\n",
      "\n",
      "Model Configurations:\n",
      "   Isolation Forest: {'contamination': 0.05, 'random_state': 42, 'n_estimators': 100}\n",
      "   One-Class SVM: {'nu': 0.05, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "   AutoEncoder: {'encoding_dim': 32, 'epochs': 50, 'batch_size': 64, 'learning_rate': 0.001}\n",
      "\n",
      "AI Agent Configurations:\n",
      "   Model Name: gemini-1.5-flash\n",
      "   Temperature: 0.7\n",
      "   Max Tokens: 2000\n",
      "   Memory Window: 10\n",
      "   MCP Server URL: http://localhost:8000\n",
      "\n",
      "Data Processing Configurations:\n",
      "   Rolling Window: 7\n",
      "   Lag Periods: [1, 2]\n",
      "   Scaling Method: standard\n",
      "   Data File: AD_data_10KPI.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "config = TelecomConfig()\n",
    "\n",
    "print(\"Configuration Details:\")\n",
    "print(f\"   Data Directory: {config.data_dir}\")\n",
    "print(f\"   Models Directory: {config.models_dir}\")\n",
    "print(f\"   Logs Directory: {config.logs_dir}\")\n",
    "print(f\"   KPI Columns: {config.data.kpi_columns}\")\n",
    "print(f\"   Contamination Rate: {config.model.contamination_rate}\")\n",
    "print(f\"   AI Model: {config.agent.model_name}\")\n",
    "print(f\"   Temperature: {config.agent.temperature}\")\n",
    "print(f\"   Debug Mode: {config.debug_mode}\")\n",
    "\n",
    "# Show model configurations\n",
    "print(\"\\nModel Configurations:\")\n",
    "print(f\"   Isolation Forest: {config.model.isolation_forest_params}\")\n",
    "print(f\"   One-Class SVM: {config.model.one_class_svm_params}\")\n",
    "print(f\"   AutoEncoder: {config.model.autoencoder_params}\")\n",
    "\n",
    "# Show agent configurations\n",
    "print(\"\\nAI Agent Configurations:\")\n",
    "print(f\"   Model Name: {config.agent.model_name}\")\n",
    "print(f\"   Temperature: {config.agent.temperature}\")\n",
    "print(f\"   Max Tokens: {config.agent.max_tokens}\")\n",
    "print(f\"   Memory Window: {config.agent.memory_window}\")\n",
    "print(f\"   MCP Server URL: {config.agent.mcp_server_url}\")\n",
    "\n",
    "# Show data processing configurations\n",
    "print(\"\\nData Processing Configurations:\")\n",
    "print(f\"   Rolling Window: {config.data.rolling_window}\")\n",
    "print(f\"   Lag Periods: {config.data.lag_periods}\")\n",
    "print(f\"   Scaling Method: {config.data.scaling_method}\")\n",
    "print(f\"   Data File: {config.data.data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff7067",
   "metadata": {},
   "source": [
    "## 3. Data Processing Pipeline\n",
    "\n",
    "The data processor handles all data loading, cleaning, and feature engineering tasks in a consistent, reusable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a23cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found telecom data at: ../../AD_data_10KPI.csv\n",
      "Loading and processing telecom data...\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - process_pipeline:301 - Starting complete data processing pipeline\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - load_data:63 - Loading data from ..\\..\\AD_data_10KPI.csv\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - load_data:63 - Loading data from ..\\..\\AD_data_10KPI.csv\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - load_data:67 - Loaded 21060 rows with 13 columns\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:91 - Starting data cleaning\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 326 outliers in RSRP\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - load_data:67 - Loaded 21060 rows with 13 columns\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:91 - Starting data cleaning\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 326 outliers in RSRP\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 149 outliers in SINR\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 156 outliers in DL_Throughput\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 224 outliers in UL_Throughput\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 271 outliers in CPU_Utilization\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 213 outliers in Active_Users\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 162 outliers in RTT\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 148 outliers in Packet_Loss\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 149 outliers in SINR\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 156 outliers in DL_Throughput\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 224 outliers in UL_Throughput\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 271 outliers in CPU_Utilization\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 213 outliers in Active_Users\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 162 outliers in RTT\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 148 outliers in Packet_Loss\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 148 outliers in Call_Drop_Rate\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 986 outliers in Handover_Success_Rate\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:132 - Data cleaning completed. Shape: (21060, 13)\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - engineer_features:146 - Starting feature engineering\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 148 outliers in Call_Drop_Rate\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:129 - Capping 986 outliers in Handover_Success_Rate\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - clean_data:132 - Data cleaning completed. Shape: (21060, 13)\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - engineer_features:146 - Starting feature engineering\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - engineer_features:197 - Feature engineering completed. New shape: (21060, 97)\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - scale_features:212 - Scaling features\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - engineer_features:197 - Feature engineering completed. New shape: (21060, 97)\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - scale_features:212 - Scaling features\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - scale_features:241 - Scaled 94 numerical features\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - process_pipeline:318 - Data processing pipeline completed successfully\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - scale_features:241 - Scaled 94 numerical features\n",
      "2025-08-06 13:07:54 - TelecomDataProcessor - INFO - process_pipeline:318 - Data processing pipeline completed successfully\n",
      "Processing complete!\n",
      "Final dataset: 21,060 records, 97 columns\n",
      "\n",
      "Data Overview:\n",
      "   • Shape: (21060, 97)\n",
      "   • Date Range: 2024-01-01 00:00:00 to 2024-02-29 00:00:00\n",
      "   • Unique Sites: 100\n",
      "\n",
      "Available KPI Columns: ['RSRP', 'SINR', 'DL_Throughput', 'UL_Throughput', 'CPU_Utilization', 'Active_Users', 'RTT', 'Packet_Loss', 'Call_Drop_Rate', 'Handover_Success_Rate']\n",
      "\n",
      "Data Quality:\n",
      "   • Missing Values: 0\n",
      "Processing complete!\n",
      "Final dataset: 21,060 records, 97 columns\n",
      "\n",
      "Data Overview:\n",
      "   • Shape: (21060, 97)\n",
      "   • Date Range: 2024-01-01 00:00:00 to 2024-02-29 00:00:00\n",
      "   • Unique Sites: 100\n",
      "\n",
      "Available KPI Columns: ['RSRP', 'SINR', 'DL_Throughput', 'UL_Throughput', 'CPU_Utilization', 'Active_Users', 'RTT', 'Packet_Loss', 'Call_Drop_Rate', 'Handover_Success_Rate']\n",
      "\n",
      "Data Quality:\n",
      "   • Missing Values: 0\n",
      "   • Duplicate Rows: 0\n",
      "   • Numeric Columns: 94\n",
      "\n",
      "Sample processed data:\n",
      "   • Duplicate Rows: 0\n",
      "   • Numeric Columns: 94\n",
      "\n",
      "Sample processed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Sector_ID</th>\n",
       "      <th>RSRP</th>\n",
       "      <th>DL_Throughput</th>\n",
       "      <th>Call_Drop_Rate</th>\n",
       "      <th>RTT</th>\n",
       "      <th>CPU_Utilization</th>\n",
       "      <th>Active_Users</th>\n",
       "      <th>SINR</th>\n",
       "      <th>...</th>\n",
       "      <th>Active_Users_diff</th>\n",
       "      <th>Active_Users_pct_change</th>\n",
       "      <th>RTT_diff</th>\n",
       "      <th>RTT_pct_change</th>\n",
       "      <th>Packet_Loss_diff</th>\n",
       "      <th>Packet_Loss_pct_change</th>\n",
       "      <th>Call_Drop_Rate_diff</th>\n",
       "      <th>Call_Drop_Rate_pct_change</th>\n",
       "      <th>Handover_Success_Rate_diff</th>\n",
       "      <th>Handover_Success_Rate_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>SITE_001</td>\n",
       "      <td>SITE_001_SECTOR_A</td>\n",
       "      <td>0.771341</td>\n",
       "      <td>0.360612</td>\n",
       "      <td>-1.212332</td>\n",
       "      <td>-0.359532</td>\n",
       "      <td>0.301916</td>\n",
       "      <td>0.041678</td>\n",
       "      <td>-0.302950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.272598</td>\n",
       "      <td>-0.150733</td>\n",
       "      <td>0.278153</td>\n",
       "      <td>-0.033217</td>\n",
       "      <td>1.604621</td>\n",
       "      <td>0.131812</td>\n",
       "      <td>-1.022789</td>\n",
       "      <td>-0.983986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>SITE_017</td>\n",
       "      <td>SITE_017_SECTOR_D</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>-0.286988</td>\n",
       "      <td>1.016553</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>-0.471732</td>\n",
       "      <td>0.583827</td>\n",
       "      <td>-0.597963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.272598</td>\n",
       "      <td>-0.150733</td>\n",
       "      <td>0.278153</td>\n",
       "      <td>-0.033217</td>\n",
       "      <td>1.604621</td>\n",
       "      <td>0.131812</td>\n",
       "      <td>-1.022789</td>\n",
       "      <td>-0.983986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>SITE_083</td>\n",
       "      <td>SITE_083_SECTOR_A</td>\n",
       "      <td>-0.545526</td>\n",
       "      <td>-0.796187</td>\n",
       "      <td>-0.633614</td>\n",
       "      <td>-1.053820</td>\n",
       "      <td>0.451403</td>\n",
       "      <td>-1.413655</td>\n",
       "      <td>0.801506</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.463579</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.778174</td>\n",
       "      <td>-0.278277</td>\n",
       "      <td>-1.270831</td>\n",
       "      <td>-0.041937</td>\n",
       "      <td>-1.188248</td>\n",
       "      <td>-0.065813</td>\n",
       "      <td>0.991867</td>\n",
       "      <td>0.953629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>SITE_082</td>\n",
       "      <td>SITE_082_SECTOR_D</td>\n",
       "      <td>0.227517</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>0.593191</td>\n",
       "      <td>-0.240660</td>\n",
       "      <td>0.428154</td>\n",
       "      <td>-0.376334</td>\n",
       "      <td>0.524812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760057</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.592060</td>\n",
       "      <td>0.080046</td>\n",
       "      <td>1.214764</td>\n",
       "      <td>0.144010</td>\n",
       "      <td>0.883136</td>\n",
       "      <td>-0.030613</td>\n",
       "      <td>-1.029942</td>\n",
       "      <td>-0.993688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>SITE_018</td>\n",
       "      <td>SITE_018_SECTOR_A</td>\n",
       "      <td>1.097028</td>\n",
       "      <td>-0.667875</td>\n",
       "      <td>-0.442088</td>\n",
       "      <td>-0.634211</td>\n",
       "      <td>0.607905</td>\n",
       "      <td>0.694285</td>\n",
       "      <td>1.142299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784454</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>-0.286578</td>\n",
       "      <td>-0.230772</td>\n",
       "      <td>-0.008059</td>\n",
       "      <td>-0.035155</td>\n",
       "      <td>-0.745535</td>\n",
       "      <td>-0.063305</td>\n",
       "      <td>0.908513</td>\n",
       "      <td>0.873019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Site_ID          Sector_ID      RSRP  DL_Throughput  \\\n",
       "0 2024-01-01  SITE_001  SITE_001_SECTOR_A  0.771341       0.360612   \n",
       "1 2024-01-01  SITE_017  SITE_017_SECTOR_D  0.565302      -0.286988   \n",
       "2 2024-01-01  SITE_083  SITE_083_SECTOR_A -0.545526      -0.796187   \n",
       "3 2024-01-01  SITE_082  SITE_082_SECTOR_D  0.227517       0.838085   \n",
       "4 2024-01-01  SITE_018  SITE_018_SECTOR_A  1.097028      -0.667875   \n",
       "\n",
       "   Call_Drop_Rate       RTT  CPU_Utilization  Active_Users      SINR  ...  \\\n",
       "0       -1.212332 -0.359532         0.301916      0.041678 -0.302950  ...   \n",
       "1        1.016553  0.014882        -0.471732      0.583827 -0.597963  ...   \n",
       "2       -0.633614 -1.053820         0.451403     -1.413655  0.801506  ...   \n",
       "3        0.593191 -0.240660         0.428154     -0.376334  0.524812  ...   \n",
       "4       -0.442088 -0.634211         0.607905      0.694285  1.142299  ...   \n",
       "\n",
       "   Active_Users_diff  Active_Users_pct_change  RTT_diff  RTT_pct_change  \\\n",
       "0           0.397238                 0.004113  0.272598       -0.150733   \n",
       "1           0.397238                 0.004113  0.272598       -0.150733   \n",
       "2          -1.463579                -0.002990 -0.778174       -0.278277   \n",
       "3           0.760057                 0.023461  0.592060        0.080046   \n",
       "4           0.784454                 0.007084 -0.286578       -0.230772   \n",
       "\n",
       "   Packet_Loss_diff  Packet_Loss_pct_change  Call_Drop_Rate_diff  \\\n",
       "0          0.278153               -0.033217             1.604621   \n",
       "1          0.278153               -0.033217             1.604621   \n",
       "2         -1.270831               -0.041937            -1.188248   \n",
       "3          1.214764                0.144010             0.883136   \n",
       "4         -0.008059               -0.035155            -0.745535   \n",
       "\n",
       "   Call_Drop_Rate_pct_change  Handover_Success_Rate_diff  \\\n",
       "0                   0.131812                   -1.022789   \n",
       "1                   0.131812                   -1.022789   \n",
       "2                  -0.065813                    0.991867   \n",
       "3                  -0.030613                   -1.029942   \n",
       "4                  -0.063305                    0.908513   \n",
       "\n",
       "   Handover_Success_Rate_pct_change  \n",
       "0                         -0.983986  \n",
       "1                         -0.983986  \n",
       "2                          0.953629  \n",
       "3                         -0.993688  \n",
       "4                          0.873019  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KPI Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSRP</th>\n",
       "      <th>SINR</th>\n",
       "      <th>DL_Throughput</th>\n",
       "      <th>UL_Throughput</th>\n",
       "      <th>CPU_Utilization</th>\n",
       "      <th>Active_Users</th>\n",
       "      <th>RTT</th>\n",
       "      <th>Packet_Loss</th>\n",
       "      <th>Call_Drop_Rate</th>\n",
       "      <th>Handover_Success_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "      <td>2.106000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.103985e-17</td>\n",
       "      <td>-9.716824e-17</td>\n",
       "      <td>-1.619471e-16</td>\n",
       "      <td>-2.699118e-18</td>\n",
       "      <td>5.398235e-17</td>\n",
       "      <td>-3.670800e-16</td>\n",
       "      <td>-1.025665e-16</td>\n",
       "      <td>8.637177e-17</td>\n",
       "      <td>-1.120134e-16</td>\n",
       "      <td>1.435931e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.456869e+00</td>\n",
       "      <td>-4.789429e+00</td>\n",
       "      <td>-4.936341e+00</td>\n",
       "      <td>-4.590658e+00</td>\n",
       "      <td>-4.467325e+00</td>\n",
       "      <td>-4.729399e+00</td>\n",
       "      <td>-4.937337e+00</td>\n",
       "      <td>-4.765661e+00</td>\n",
       "      <td>-4.899797e+00</td>\n",
       "      <td>-3.594541e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.114288e-01</td>\n",
       "      <td>-7.044809e-01</td>\n",
       "      <td>-7.305384e-01</td>\n",
       "      <td>-6.852334e-01</td>\n",
       "      <td>-6.803770e-01</td>\n",
       "      <td>-6.969068e-01</td>\n",
       "      <td>-7.434786e-01</td>\n",
       "      <td>-7.448758e-01</td>\n",
       "      <td>-7.566199e-01</td>\n",
       "      <td>-5.409710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.317204e-03</td>\n",
       "      <td>-2.448978e-03</td>\n",
       "      <td>-4.780907e-02</td>\n",
       "      <td>-1.395462e-02</td>\n",
       "      <td>-3.840335e-02</td>\n",
       "      <td>-3.710175e-02</td>\n",
       "      <td>-2.707424e-02</td>\n",
       "      <td>-1.192006e-01</td>\n",
       "      <td>-8.925452e-02</td>\n",
       "      <td>-2.281020e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.703845e-01</td>\n",
       "      <td>6.571685e-01</td>\n",
       "      <td>6.713958e-01</td>\n",
       "      <td>6.165747e-01</td>\n",
       "      <td>5.819389e-01</td>\n",
       "      <td>6.472573e-01</td>\n",
       "      <td>6.544742e-01</td>\n",
       "      <td>5.953859e-01</td>\n",
       "      <td>6.244391e-01</td>\n",
       "      <td>4.768856e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.515824e+00</td>\n",
       "      <td>4.742117e+00</td>\n",
       "      <td>4.877198e+00</td>\n",
       "      <td>4.521999e+00</td>\n",
       "      <td>4.368887e+00</td>\n",
       "      <td>4.679750e+00</td>\n",
       "      <td>4.848333e+00</td>\n",
       "      <td>4.616171e+00</td>\n",
       "      <td>4.767616e+00</td>\n",
       "      <td>3.530456e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RSRP          SINR  DL_Throughput  UL_Throughput  \\\n",
       "count  2.106000e+04  2.106000e+04   2.106000e+04   2.106000e+04   \n",
       "mean   3.103985e-17 -9.716824e-17  -1.619471e-16  -2.699118e-18   \n",
       "std    1.000024e+00  1.000024e+00   1.000024e+00   1.000024e+00   \n",
       "min   -4.456869e+00 -4.789429e+00  -4.936341e+00  -4.590658e+00   \n",
       "25%   -6.114288e-01 -7.044809e-01  -7.305384e-01  -6.852334e-01   \n",
       "50%    7.317204e-03 -2.448978e-03  -4.780907e-02  -1.395462e-02   \n",
       "75%    6.703845e-01  6.571685e-01   6.713958e-01   6.165747e-01   \n",
       "max    4.515824e+00  4.742117e+00   4.877198e+00   4.521999e+00   \n",
       "\n",
       "       CPU_Utilization  Active_Users           RTT   Packet_Loss  \\\n",
       "count     2.106000e+04  2.106000e+04  2.106000e+04  2.106000e+04   \n",
       "mean      5.398235e-17 -3.670800e-16 -1.025665e-16  8.637177e-17   \n",
       "std       1.000024e+00  1.000024e+00  1.000024e+00  1.000024e+00   \n",
       "min      -4.467325e+00 -4.729399e+00 -4.937337e+00 -4.765661e+00   \n",
       "25%      -6.803770e-01 -6.969068e-01 -7.434786e-01 -7.448758e-01   \n",
       "50%      -3.840335e-02 -3.710175e-02 -2.707424e-02 -1.192006e-01   \n",
       "75%       5.819389e-01  6.472573e-01  6.544742e-01  5.953859e-01   \n",
       "max       4.368887e+00  4.679750e+00  4.848333e+00  4.616171e+00   \n",
       "\n",
       "       Call_Drop_Rate  Handover_Success_Rate  \n",
       "count    2.106000e+04           2.106000e+04  \n",
       "mean    -1.120134e-16           1.435931e-15  \n",
       "std      1.000024e+00           1.000024e+00  \n",
       "min     -4.899797e+00          -3.594541e+00  \n",
       "25%     -7.566199e-01          -5.409710e-01  \n",
       "50%     -8.925452e-02          -2.281020e-02  \n",
       "75%      6.244391e-01           4.768856e-01  \n",
       "max      4.767616e+00           3.530456e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KPI Summary from Processor:\n",
      "   • RSRP: {'mean': -97.37618054960544, 'std': 49.14999365796192, 'min': -2976.9420680580783, 'max': 273.44298943265443, 'missing_count': 0}\n",
      "   • SINR: {'mean': 10.42276476113978, 'std': 16.343734381809796, 'min': -284.7362892618537, 'max': 216.1497834830919, 'missing_count': 0}\n",
      "   • DL_Throughput: {'mean': 56.16882076417629, 'std': 37.73991956611359, 'min': -502.5920777562853, 'max': 796.7692986768013, 'missing_count': 0}\n",
      "   • UL_Throughput: {'mean': 29.954623594654205, 'std': 26.00493104407791, 'min': -214.1059976521092, 'max': 1172.5185817684776, 'missing_count': 0}\n",
      "   • CPU_Utilization: {'mean': 52.777570971408, 'std': 28.963308140982026, 'min': -155.640425874902, 'max': 515.0202765348936, 'missing_count': 0}\n",
      "   • Active_Users: {'mean': 583.1640284780689, 'std': 383.6235873267619, 'min': -6337.845384731111, 'max': 4489.936007796935, 'missing_count': 0}\n",
      "   • RTT: {'mean': 26.40063210421205, 'std': 21.819920471106006, 'min': -216.1898203632041, 'max': 564.3952567639444, 'missing_count': 0}\n",
      "   • Packet_Loss: {'mean': 1.7233109779859848, 'std': 1.5929213124124157, 'min': -27.937603307133248, 'max': 43.28095017301133, 'missing_count': 0}\n",
      "   • Call_Drop_Rate: {'mean': 2.9309114625916846, 'std': 2.3424533782225043, 'min': -21.446339544008623, 'max': 60.34919338430181, 'missing_count': 0}\n",
      "   • Handover_Success_Rate: {'mean': 95.38139360083915, 'std': 47.18961295354579, 'min': -2375.430708791103, 'max': 1187.055815829078, 'missing_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize data processor\n",
    "data_processor = TelecomDataProcessor(config)\n",
    "\n",
    "# Load the actual telecom data - check multiple possible locations\n",
    "possible_data_paths = [\n",
    "    \"../../AD_data_10KPI.csv\",  # From notebooks folder, go up two levels\n",
    "    \"../data/AD_data_10KPI.csv\",  # From notebooks folder to platform data folder\n",
    "    os.path.join(config.data_dir, \"AD_data_10KPI.csv\"),  # Using config data directory\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for path in possible_data_paths:\n",
    "    if os.path.exists(path):\n",
    "        data_path = path\n",
    "        break\n",
    "\n",
    "if data_path:\n",
    "    print(f\"Found telecom data at: {data_path}\")\n",
    "    print(\"Loading and processing telecom data...\")\n",
    "    \n",
    "    # Use the complete processing pipeline (this loads, cleans, engineers features, and scales)\n",
    "    processed_data = data_processor.process_pipeline(data_path)\n",
    "    \n",
    "    print(f\"Processing complete!\")\n",
    "    print(f\"Final dataset: {len(processed_data):,} records, {len(processed_data.columns)} columns\")\n",
    "    \n",
    "    # Show data information\n",
    "    print(f\"\\nData Overview:\")\n",
    "    print(f\"   • Shape: {processed_data.shape}\")\n",
    "    if 'Date' in processed_data.columns:\n",
    "        print(f\"   • Date Range: {processed_data['Date'].min()} to {processed_data['Date'].max()}\")\n",
    "    if 'Site_ID' in processed_data.columns:\n",
    "        print(f\"   • Unique Sites: {processed_data['Site_ID'].nunique()}\")\n",
    "    \n",
    "    # Show available KPI columns\n",
    "    available_kpis = [col for col in config.data.kpi_columns if col in processed_data.columns]\n",
    "    print(f\"\\nAvailable KPI Columns: {available_kpis}\")\n",
    "    \n",
    "    # Show basic data quality information\n",
    "    print(f\"\\nData Quality:\")\n",
    "    print(f\"   • Missing Values: {processed_data.isnull().sum().sum()}\")\n",
    "    print(f\"   • Duplicate Rows: {processed_data.duplicated().sum()}\")\n",
    "    print(f\"   • Numeric Columns: {len(processed_data.select_dtypes(include=[np.number]).columns)}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nSample processed data:\")\n",
    "    display(processed_data.head())\n",
    "    \n",
    "    # Show basic statistics for KPIs\n",
    "    if available_kpis:\n",
    "        print(\"\\nKPI Statistics:\")\n",
    "        kpi_stats = processed_data[available_kpis].describe()\n",
    "        display(kpi_stats)\n",
    "    \n",
    "    # Get summary from the processor\n",
    "    try:\n",
    "        summary = data_processor.get_kpi_summary()\n",
    "        print(f\"\\nKPI Summary from Processor:\")\n",
    "        for kpi, stats in summary.items():\n",
    "            if isinstance(stats, dict):\n",
    "                print(f\"   • {kpi}: {stats}\")\n",
    "            else:\n",
    "                print(f\"   • {kpi}: {stats}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   • Note: KPI summary not available yet (needs processed data stored)\")\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR: AD_data_10KPI.csv not found in any expected location!\")\n",
    "    print(\"Searched paths:\")\n",
    "    for path in possible_data_paths:\n",
    "        print(f\"   • {path} - {'EXISTS' if os.path.exists(path) else 'NOT FOUND'}\")\n",
    "    \n",
    "    print(\"\\nCurrent working directory contents:\")\n",
    "    for item in os.listdir('.'):\n",
    "        print(f\"   • {item}\")\n",
    "    \n",
    "    raise FileNotFoundError(\"Cannot find the telecom data file. Please check the file location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b0786",
   "metadata": {},
   "source": [
    "## 4. Anomaly Detection Models\n",
    "\n",
    "The platform uses KPI-specific anomaly detection models, automatically selecting the best algorithm for each type of metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c1b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "KPI-Specific Algorithm Mapping:\n",
      "  RSRP: isolation_forest\n",
      "  SINR: autoencoder\n",
      "  DL_Throughput: isolation_forest\n",
      "  UL_Throughput: isolation_forest\n",
      "  CPU_Utilization: one_class_svm\n",
      "  Active_Users: gaussian_mixture\n",
      "  RTT: isolation_forest\n",
      "  Packet_Loss: one_class_svm\n",
      "  Call_Drop_Rate: one_class_svm\n",
      "  Handover_Success_Rate: gaussian_mixture\n",
      "\n",
      "Training anomaly detection models...\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:421 - Starting training for all KPI detectors\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RSRP\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "KPI-Specific Algorithm Mapping:\n",
      "  RSRP: isolation_forest\n",
      "  SINR: autoencoder\n",
      "  DL_Throughput: isolation_forest\n",
      "  UL_Throughput: isolation_forest\n",
      "  CPU_Utilization: one_class_svm\n",
      "  Active_Users: gaussian_mixture\n",
      "  RTT: isolation_forest\n",
      "  Packet_Loss: one_class_svm\n",
      "  Call_Drop_Rate: one_class_svm\n",
      "  Handover_Success_Rate: gaussian_mixture\n",
      "\n",
      "Training anomaly detection models...\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:421 - Starting training for all KPI detectors\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RSRP\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:207 - Training completed for RSRP\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:426 - Training detector for SINR\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:190 - Training autoencoder on 21060 samples\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:207 - Training completed for RSRP\n",
      "2025-08-06 13:09:05 - KPIAnomalyDetector - INFO - fit:426 - Training detector for SINR\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "2025-08-06 13:09:05 - KPISpecificDetector - INFO - fit:190 - Training autoencoder on 21060 samples\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for SINR\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for DL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for DL_Throughput on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for SINR\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for DL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for DL_Throughput on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for DL_Throughput\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for UL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for UL_Throughput on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for DL_Throughput\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for UL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for UL_Throughput on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for UL_Throughput\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for CPU_Utilization\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for CPU_Utilization on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:207 - Training completed for UL_Throughput\n",
      "2025-08-06 13:09:07 - KPIAnomalyDetector - INFO - fit:426 - Training detector for CPU_Utilization\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for CPU_Utilization on cuda\n",
      "2025-08-06 13:09:07 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - fit:207 - Training completed for CPU_Utilization\n",
      "2025-08-06 13:09:09 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Active_Users\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Active_Users on cuda\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - fit:207 - Training completed for CPU_Utilization\n",
      "2025-08-06 13:09:09 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Active_Users\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Active_Users on cuda\n",
      "2025-08-06 13:09:09 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - fit:207 - Training completed for Active_Users\n",
      "2025-08-06 13:09:12 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RTT\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RTT on cuda\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - fit:207 - Training completed for Active_Users\n",
      "2025-08-06 13:09:12 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RTT\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RTT on cuda\n",
      "2025-08-06 13:09:12 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - fit:207 - Training completed for RTT\n",
      "2025-08-06 13:09:13 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Packet_Loss\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Packet_Loss on cuda\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - fit:207 - Training completed for RTT\n",
      "2025-08-06 13:09:13 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Packet_Loss\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Packet_Loss on cuda\n",
      "2025-08-06 13:09:13 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - fit:207 - Training completed for Packet_Loss\n",
      "2025-08-06 13:09:14 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Call_Drop_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Call_Drop_Rate on cuda\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - fit:207 - Training completed for Packet_Loss\n",
      "2025-08-06 13:09:14 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Call_Drop_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Call_Drop_Rate on cuda\n",
      "2025-08-06 13:09:14 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:207 - Training completed for Call_Drop_Rate\n",
      "2025-08-06 13:09:16 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Handover_Success_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Handover_Success_Rate on cuda\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:207 - Training completed for Call_Drop_Rate\n",
      "2025-08-06 13:09:16 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Handover_Success_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Handover_Success_Rate on cuda\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:207 - Training completed for Handover_Success_Rate\n",
      "2025-08-06 13:09:16 - KPIAnomalyDetector - INFO - fit:441 - Training completed for 10 KPI detectors\n",
      "Training completed!\n",
      "\n",
      "Trained Models Summary:\n",
      "  RSRP:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5863\n",
      "    Status: Fitted\n",
      "  SINR:\n",
      "    Algorithm: autoencoder\n",
      "    Threshold: 25.6077\n",
      "    Status: Fitted\n",
      "  DL_Throughput:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5637\n",
      "    Status: Fitted\n",
      "  UL_Throughput:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5651\n",
      "    Status: Fitted\n",
      "  CPU_Utilization:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -47.6020\n",
      "    Status: Fitted\n",
      "  Active_Users:\n",
      "    Algorithm: gaussian_mixture\n",
      "    Threshold: 98.9602\n",
      "    Status: Fitted\n",
      "  RTT:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5588\n",
      "    Status: Fitted\n",
      "  Packet_Loss:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -48.8579\n",
      "    Status: Fitted\n",
      "  Call_Drop_Rate:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -52.0632\n",
      "    Status: Fitted\n",
      "  Handover_Success_Rate:\n",
      "    Algorithm: gaussian_mixture\n",
      "    Threshold: 91.4973\n",
      "    Status: Fitted\n",
      "2025-08-06 13:09:16 - KPISpecificDetector - INFO - fit:207 - Training completed for Handover_Success_Rate\n",
      "2025-08-06 13:09:16 - KPIAnomalyDetector - INFO - fit:441 - Training completed for 10 KPI detectors\n",
      "Training completed!\n",
      "\n",
      "Trained Models Summary:\n",
      "  RSRP:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5863\n",
      "    Status: Fitted\n",
      "  SINR:\n",
      "    Algorithm: autoencoder\n",
      "    Threshold: 25.6077\n",
      "    Status: Fitted\n",
      "  DL_Throughput:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5637\n",
      "    Status: Fitted\n",
      "  UL_Throughput:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5651\n",
      "    Status: Fitted\n",
      "  CPU_Utilization:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -47.6020\n",
      "    Status: Fitted\n",
      "  Active_Users:\n",
      "    Algorithm: gaussian_mixture\n",
      "    Threshold: 98.9602\n",
      "    Status: Fitted\n",
      "  RTT:\n",
      "    Algorithm: isolation_forest\n",
      "    Threshold: 0.5588\n",
      "    Status: Fitted\n",
      "  Packet_Loss:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -48.8579\n",
      "    Status: Fitted\n",
      "  Call_Drop_Rate:\n",
      "    Algorithm: one_class_svm\n",
      "    Threshold: -52.0632\n",
      "    Status: Fitted\n",
      "  Handover_Success_Rate:\n",
      "    Algorithm: gaussian_mixture\n",
      "    Threshold: 91.4973\n",
      "    Status: Fitted\n"
     ]
    }
   ],
   "source": [
    "# Initialize anomaly detector\n",
    "anomaly_detector = KPIAnomalyDetector(config)\n",
    "\n",
    "# Import the specific detector class to access the algorithm mapping\n",
    "from telecom_ai_platform.models.anomaly_detector import KPISpecificDetector\n",
    "\n",
    "print(\"KPI-Specific Algorithm Mapping:\")\n",
    "for kpi, algorithm in KPISpecificDetector.KPI_ALGORITHM_MAP.items():\n",
    "    print(f\"  {kpi}: {algorithm}\")\n",
    "\n",
    "# Train the anomaly detection models\n",
    "print(\"\\nTraining anomaly detection models...\")\n",
    "anomaly_detector.fit(processed_data)\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Get model summary\n",
    "model_summary = anomaly_detector.get_model_summary()\n",
    "print(\"\\nTrained Models Summary:\")\n",
    "for kpi, details in model_summary.items():\n",
    "    print(f\"  {kpi}:\")\n",
    "    print(f\"    Algorithm: {details['algorithm']}\")\n",
    "    print(f\"    Threshold: {details['threshold']:.4f}\")\n",
    "    print(f\"    Status: {'Fitted' if details['is_fitted'] else 'Not Fitted'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "045e2372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting anomalies...\n",
      "2025-08-06 13:09:35 - KPIAnomalyDetector - INFO - detect_anomalies:514 - Detected 7381 anomalies out of 210600 samples\n",
      "2025-08-06 13:09:35 - KPIAnomalyDetector - INFO - detect_anomalies:514 - Detected 7381 anomalies out of 210600 samples\n",
      "\n",
      "Anomaly Detection Results:\n",
      "  Total Samples: 210,600\n",
      "  Anomalies Detected: 7,381\n",
      "  Anomaly Rate: 3.50%\n",
      "\n",
      "Severity Breakdown:\n",
      "  Low: 4,214\n",
      "  Medium: 2\n",
      "  High: 3,165\n",
      "\n",
      "Top 5 Anomalies:\n",
      "  1. Active_Users at SITE_001\n",
      "     Value: 0.04, Score: 7062.568\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  2. Handover_Success_Rate at SITE_001\n",
      "     Value: 0.78, Score: 6643.030\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  3. SINR at SITE_006\n",
      "     Value: -1.41, Score: 1771.882\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  4. Active_Users at SITE_028\n",
      "     Value: 0.83, Score: 1727.893\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  5. Active_Users at SITE_065\n",
      "     Value: 0.88, Score: 127.994\n",
      "     Severity: LOW, Confidence: 29.3%\n",
      "\n",
      "Anomaly Detection Results:\n",
      "  Total Samples: 210,600\n",
      "  Anomalies Detected: 7,381\n",
      "  Anomaly Rate: 3.50%\n",
      "\n",
      "Severity Breakdown:\n",
      "  Low: 4,214\n",
      "  Medium: 2\n",
      "  High: 3,165\n",
      "\n",
      "Top 5 Anomalies:\n",
      "  1. Active_Users at SITE_001\n",
      "     Value: 0.04, Score: 7062.568\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  2. Handover_Success_Rate at SITE_001\n",
      "     Value: 0.78, Score: 6643.030\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  3. SINR at SITE_006\n",
      "     Value: -1.41, Score: 1771.882\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  4. Active_Users at SITE_028\n",
      "     Value: 0.83, Score: 1727.893\n",
      "     Severity: HIGH, Confidence: 100.0%\n",
      "  5. Active_Users at SITE_065\n",
      "     Value: 0.88, Score: 127.994\n",
      "     Severity: LOW, Confidence: 29.3%\n"
     ]
    }
   ],
   "source": [
    "# Detect anomalies in the data\n",
    "print(\"Detecting anomalies...\")\n",
    "\n",
    "# Detect anomalies for all KPIs\n",
    "anomaly_results = anomaly_detector.detect_anomalies(processed_data)\n",
    "\n",
    "# Analyze results\n",
    "total_samples = len(anomaly_results)\n",
    "anomalies = [r for r in anomaly_results if r.is_anomaly]\n",
    "anomaly_rate = len(anomalies) / total_samples if total_samples > 0 else 0\n",
    "\n",
    "print(f\"\\nAnomaly Detection Results:\")\n",
    "print(f\"  Total Samples: {total_samples:,}\")\n",
    "print(f\"  Anomalies Detected: {len(anomalies):,}\")\n",
    "print(f\"  Anomaly Rate: {anomaly_rate:.2%}\")\n",
    "\n",
    "# Breakdown by severity\n",
    "severity_counts = {}\n",
    "for severity in ['low', 'medium', 'high']:\n",
    "    count = sum(1 for a in anomalies if a.severity == severity)\n",
    "    severity_counts[severity] = count\n",
    "\n",
    "print(f\"\\nSeverity Breakdown:\")\n",
    "for severity, count in severity_counts.items():\n",
    "    print(f\"  {severity.capitalize()}: {count:,}\")\n",
    "\n",
    "# Show top anomalies\n",
    "if anomalies:\n",
    "    print(f\"\\nTop 5 Anomalies:\")\n",
    "    top_anomalies = sorted(anomalies, key=lambda x: x.anomaly_score, reverse=True)[:5]\n",
    "    \n",
    "    for i, anomaly in enumerate(top_anomalies, 1):\n",
    "        print(f\"  {i}. {anomaly.kpi_name} at {anomaly.site_id}\")\n",
    "        print(f\"     Value: {anomaly.value:.2f}, Score: {anomaly.anomaly_score:.3f}\")\n",
    "        print(f\"     Severity: {anomaly.severity.upper()}, Confidence: {anomaly.confidence:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3422b",
   "metadata": {},
   "source": [
    "## 5. Visualization Capabilities\n",
    "\n",
    "The platform provides rich visualization capabilities for data analysis and anomaly detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5dc80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating visualizations...\n",
      "\n",
      " Summary Report:\n",
      "Data Overview:\n",
      "  total_records: 21060\n",
      "  date_range: ['2024-01-01 00:00:00', '2024-02-29 00:00:00']\n",
      "  sites_count: 100\n",
      "  kpis_analyzed: 10\n",
      "\n",
      "Anomaly Summary:\n",
      "  total_anomalies: 7381\n",
      "  anomaly_rate: 0.035047483380816716\n",
      "  severity_distribution: {'low': 4214, 'medium': 2, 'high': 3165}\n",
      "\n",
      "KPI Breakdown:\n",
      "  RSRP: 1053/21060 (5.0%)\n",
      "  SINR: 6/21060 (0.0%)\n",
      "  DL_Throughput: 1053/21060 (5.0%)\n",
      "  UL_Throughput: 1053/21060 (5.0%)\n",
      "  CPU_Utilization: 1053/21060 (5.0%)\n",
      "  Active_Users: 3/21060 (0.0%)\n",
      "  RTT: 1053/21060 (5.0%)\n",
      "  Packet_Loss: 1053/21060 (5.0%)\n",
      "  Call_Drop_Rate: 1053/21060 (5.0%)\n",
      "  Handover_Success_Rate: 1/21060 (0.0%)\n",
      "\n",
      " Summary Report:\n",
      "Data Overview:\n",
      "  total_records: 21060\n",
      "  date_range: ['2024-01-01 00:00:00', '2024-02-29 00:00:00']\n",
      "  sites_count: 100\n",
      "  kpis_analyzed: 10\n",
      "\n",
      "Anomaly Summary:\n",
      "  total_anomalies: 7381\n",
      "  anomaly_rate: 0.035047483380816716\n",
      "  severity_distribution: {'low': 4214, 'medium': 2, 'high': 3165}\n",
      "\n",
      "KPI Breakdown:\n",
      "  RSRP: 1053/21060 (5.0%)\n",
      "  SINR: 6/21060 (0.0%)\n",
      "  DL_Throughput: 1053/21060 (5.0%)\n",
      "  UL_Throughput: 1053/21060 (5.0%)\n",
      "  CPU_Utilization: 1053/21060 (5.0%)\n",
      "  Active_Users: 3/21060 (0.0%)\n",
      "  RTT: 1053/21060 (5.0%)\n",
      "  Packet_Loss: 1053/21060 (5.0%)\n",
      "  Call_Drop_Rate: 1053/21060 (5.0%)\n",
      "  Handover_Success_Rate: 1/21060 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = TelecomVisualizer(config)\n",
    "\n",
    "print(\" Creating visualizations...\")\n",
    "\n",
    "# Generate summary report\n",
    "summary_report = visualizer.generate_summary_report(processed_data, anomaly_results)\n",
    "\n",
    "print(\"\\n Summary Report:\")\n",
    "print(f\"Data Overview:\")\n",
    "for key, value in summary_report['data_overview'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nAnomaly Summary:\")\n",
    "for key, value in summary_report['anomaly_summary'].items():\n",
    "    if key != 'kpi_breakdown':\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nKPI Breakdown:\")\n",
    "for kpi, stats in summary_report['anomaly_summary']['kpi_breakdown'].items():\n",
    "    print(f\"  {kpi}: {stats['anomalies']}/{stats['total_samples']} ({stats['anomaly_rate']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a91af",
   "metadata": {},
   "source": [
    "## 6. Conversational AI Agent\n",
    "\n",
    "The platform includes a sophisticated conversational AI agent that can understand natural language queries about network data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d800ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conversational AI Agent Capabilities:\n",
      "\n",
      " Example Queries:\n",
      "  1. Show me the performance trends for RSRP\n",
      "  2. Find anomalies in throughput for the last week\n",
      "  3. Compare SINR performance between sites 001 and 002\n",
      "  4. What's the average CPU utilization across all sites?\n",
      "  5. Analyze the data quality for upload throughput\n",
      "  6. Detect high-severity anomalies in signal strength\n",
      "\n",
      " Available Tools:\n",
      "   LoadNetworkData: Load and process telecom data files\n",
      "   AnalyzeKPITrends: Analyze performance trends for specific KPIs\n",
      "   DetectAnomalies: Detect and analyze network anomalies\n",
      "   GetSiteOverview: Get comprehensive site performance overview\n",
      "   CompareSites: Compare KPI performance across multiple sites\n",
      "\n",
      " Example Conversation:\n",
      "User: 'Show me anomalies in RSRP for site SITE_001'\n",
      "Agent: 'I found 12 RSRP anomalies for SITE_001. Here's the analysis...'\n",
      "       - 3 high-severity anomalies (values below -110 dBm)\n",
      "       - 5 medium-severity anomalies (values -105 to -110 dBm)\n",
      "       - 4 low-severity anomalies (statistical outliers)\n",
      "       'Would you like me to create a visualization or investigate specific time periods?'\n"
     ]
    }
   ],
   "source": [
    "# Note: The conversational AI requires a valid Google Gemini API key\n",
    "# For demonstration, we'll show the structure without making actual API calls\n",
    "\n",
    "print(\" Conversational AI Agent Capabilities:\")\n",
    "print(\"\\n Example Queries:\")\n",
    "example_queries = [\n",
    "    \"Show me the performance trends for RSRP\",\n",
    "    \"Find anomalies in throughput for the last week\",\n",
    "    \"Compare SINR performance between sites 001 and 002\",\n",
    "    \"What's the average CPU utilization across all sites?\",\n",
    "    \"Analyze the data quality for upload throughput\",\n",
    "    \"Detect high-severity anomalies in signal strength\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(example_queries, 1):\n",
    "    print(f\"  {i}. {query}\")\n",
    "\n",
    "print(\"\\n Available Tools:\")\n",
    "tools_description = {\n",
    "    \"LoadNetworkData\": \"Load and process telecom data files\",\n",
    "    \"AnalyzeKPITrends\": \"Analyze performance trends for specific KPIs\",\n",
    "    \"DetectAnomalies\": \"Detect and analyze network anomalies\",\n",
    "    \"GetSiteOverview\": \"Get comprehensive site performance overview\",\n",
    "    \"CompareSites\": \"Compare KPI performance across multiple sites\"\n",
    "}\n",
    "\n",
    "for tool, description in tools_description.items():\n",
    "    print(f\"   {tool}: {description}\")\n",
    "\n",
    "# Simulated conversation example\n",
    "print(\"\\n Example Conversation:\")\n",
    "print(\"User: 'Show me anomalies in RSRP for site SITE_001'\")\n",
    "print(\"Agent: 'I found 12 RSRP anomalies for SITE_001. Here's the analysis...'\")\n",
    "print(\"       - 3 high-severity anomalies (values below -110 dBm)\")\n",
    "print(\"       - 5 medium-severity anomalies (values -105 to -110 dBm)\")\n",
    "print(\"       - 4 low-severity anomalies (statistical outliers)\")\n",
    "print(\"       'Would you like me to create a visualization or investigate specific time periods?'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d50277",
   "metadata": {},
   "source": [
    "## 7. Complete Platform Interface\n",
    "\n",
    "The `TelecomAIPlatform` class provides a unified interface to all platform capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5271252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:11:22 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:11:22 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:11:22 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:11:22 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - load_model:386 - Model loaded from c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - load_model:386 - Model loaded from c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - TelecomAPIServer - WARNING - _load_models:150 - Could not load models: Error(s) in loading state_dict for AutoEncoder:\n",
      "\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([8, 9]) from checkpoint, the shape in current model is torch.Size([16, 9]).\n",
      "\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([4, 8]) from checkpoint, the shape in current model is torch.Size([8, 16]).\n",
      "\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([8, 4]) from checkpoint, the shape in current model is torch.Size([16, 8]).\n",
      "\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([9, 8]) from checkpoint, the shape in current model is torch.Size([9, 16]).\n",
      "2025-08-06 13:11:22 - TelecomAIPlatform - INFO - __init__:44 - Telecom AI Platform initialized successfully\n",
      " Telecom AI Platform v2.0 Initialized!\n",
      "\n",
      " Platform Status:\n",
      "  config:\n",
      "    data_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\data\n",
      "    models_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\n",
      "    logs_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\logs\n",
      "  models_loaded: False\n",
      "  agent_ready: True\n",
      "  server_ready: True\n",
      "\n",
      " Available Platform Methods:\n",
      "   platform.train_models(data_path)\n",
      "   platform.chat(message)\n",
      "   platform.start_server(host, port)\n",
      "   platform.load_models()\n",
      "   platform.get_status()\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:11:22 - TelecomAPIServer - WARNING - _load_models:150 - Could not load models: Error(s) in loading state_dict for AutoEncoder:\n",
      "\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([8, 9]) from checkpoint, the shape in current model is torch.Size([16, 9]).\n",
      "\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([4, 8]) from checkpoint, the shape in current model is torch.Size([8, 16]).\n",
      "\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([8, 4]) from checkpoint, the shape in current model is torch.Size([16, 8]).\n",
      "\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([9, 8]) from checkpoint, the shape in current model is torch.Size([9, 16]).\n",
      "2025-08-06 13:11:22 - TelecomAIPlatform - INFO - __init__:44 - Telecom AI Platform initialized successfully\n",
      " Telecom AI Platform v2.0 Initialized!\n",
      "\n",
      " Platform Status:\n",
      "  config:\n",
      "    data_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\data\n",
      "    models_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\n",
      "    logs_dir: c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\logs\n",
      "  models_loaded: False\n",
      "  agent_ready: True\n",
      "  server_ready: True\n",
      "\n",
      " Available Platform Methods:\n",
      "   platform.train_models(data_path)\n",
      "   platform.chat(message)\n",
      "   platform.start_server(host, port)\n",
      "   platform.load_models()\n",
      "   platform.get_status()\n"
     ]
    }
   ],
   "source": [
    "# Initialize the complete platform\n",
    "platform = TelecomAIPlatform(config)\n",
    "\n",
    "print(\" Telecom AI Platform v2.0 Initialized!\")\n",
    "\n",
    "# Get platform status\n",
    "status = platform.get_status()\n",
    "\n",
    "print(\"\\n Platform Status:\")\n",
    "for key, value in status.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"    {sub_key}: {sub_value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n Available Platform Methods:\")\n",
    "methods = [\n",
    "    \"train_models(data_path)\",\n",
    "    \"chat(message)\", \n",
    "    \"start_server(host, port)\",\n",
    "    \"load_models()\",\n",
    "    \"get_status()\"\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"   platform.{method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5691d5b",
   "metadata": {},
   "source": [
    "## 8. Model Training Pipeline\n",
    "\n",
    "The platform includes a comprehensive training pipeline with validation and performance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4258abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "from telecom_ai_platform.models.trainer import ModelTrainer, ModelPerformanceTracker\n",
    "\n",
    "trainer = ModelTrainer(config)\n",
    "performance_tracker = ModelPerformanceTracker(config)\n",
    "\n",
    "print(\" Model Training Pipeline\")\n",
    "\n",
    "# Simulate training data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data for training demonstration\n",
    "train_data, test_data = train_test_split(processed_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n Data Splits:\")\n",
    "print(f\"  Training: {len(train_data):,} samples\")\n",
    "print(f\"  Validation: {len(val_data):,} samples\")\n",
    "print(f\"  Test: {len(test_data):,} samples\")\n",
    "\n",
    "# Train new detector on training data\n",
    "print(\"\\n Training new anomaly detector...\")\n",
    "new_detector = trainer.train_anomaly_detector(train_data, val_data)\n",
    "\n",
    "print(\" Training completed!\")\n",
    "\n",
    "# Evaluate on test data\n",
    "print(\"\\n Evaluating on test data...\")\n",
    "test_results = new_detector.detect_anomalies(test_data)\n",
    "performance_metrics = performance_tracker.evaluate_anomaly_detector(new_detector, test_data)\n",
    "\n",
    "print(f\"\\n Performance Metrics:\")\n",
    "print(f\"  Total Test Samples: {performance_metrics['total_samples']:,}\")\n",
    "print(f\"  Anomalies Detected: {performance_metrics['anomalies_detected']:,}\")\n",
    "print(f\"  Anomaly Rate: {performance_metrics['anomaly_rate']:.2%}\")\n",
    "print(f\"  Average Anomaly Score: {performance_metrics['average_anomaly_score']:.4f}\")\n",
    "\n",
    "# Show confidence distribution\n",
    "conf_dist = performance_metrics['confidence_distribution']\n",
    "print(f\"\\n Confidence Distribution:\")\n",
    "print(f\"  Mean: {conf_dist['mean']:.3f}\")\n",
    "print(f\"  Range: {conf_dist['min']:.3f} - {conf_dist['max']:.3f}\")\n",
    "print(f\"  Median: {conf_dist['q50']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea94a3",
   "metadata": {},
   "source": [
    "## 9. API Server Demonstration\n",
    "\n",
    "The platform includes a complete FastAPI server for web-based access to all capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f09130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FastAPI Server Capabilities\n",
      "\n",
      " Available Endpoints:\n",
      "  GET /: API information and health check\n",
      "  GET /status: System status and component health\n",
      "  POST /chat: Conversational AI interaction\n",
      "  POST /anomaly-detection: Detect anomalies in data\n",
      "  POST /upload-data: Upload and process data files\n",
      "  POST /train: Start model training pipeline\n",
      "  GET /training/{id}: Check training status\n",
      "  GET /models/summary: Get models information\n",
      "  GET /data/summary: Get current data summary\n",
      "  DELETE /reset: Reset system state\n",
      "\n",
      " Example API Usage:\n",
      "  curl -X POST 'http://localhost:8000/chat' -d '{\"message\": \"Show RSRP trends\"}'\n",
      "  curl -X POST 'http://localhost:8000/anomaly-detection' -d '{\"kpi_name\": \"RSRP\"}'\n",
      "  curl -X POST 'http://localhost:8000/upload-data' -F 'file=@data.csv'\n",
      "  curl -X GET 'http://localhost:8000/status'\n",
      "\n",
      " To start the server:\n",
      "  python -m telecom_ai_platform.main server --port 8000\n",
      "  Then visit: http://localhost:8000/docs for interactive API documentation\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate API structure (without actually starting the server)\n",
    "from telecom_ai_platform.server.api import TelecomAPIServer\n",
    "\n",
    "print(\" FastAPI Server Capabilities\")\n",
    "\n",
    "api_endpoints = {\n",
    "    \"GET /\": \"API information and health check\",\n",
    "    \"GET /status\": \"System status and component health\",\n",
    "    \"POST /chat\": \"Conversational AI interaction\",\n",
    "    \"POST /anomaly-detection\": \"Detect anomalies in data\",\n",
    "    \"POST /upload-data\": \"Upload and process data files\",\n",
    "    \"POST /train\": \"Start model training pipeline\",\n",
    "    \"GET /training/{id}\": \"Check training status\",\n",
    "    \"GET /models/summary\": \"Get models information\",\n",
    "    \"GET /data/summary\": \"Get current data summary\",\n",
    "    \"DELETE /reset\": \"Reset system state\"\n",
    "}\n",
    "\n",
    "print(\"\\n Available Endpoints:\")\n",
    "for endpoint, description in api_endpoints.items():\n",
    "    print(f\"  {endpoint}: {description}\")\n",
    "\n",
    "print(\"\\n Example API Usage:\")\n",
    "api_examples = [\n",
    "    \"curl -X POST 'http://localhost:8000/chat' -d '{\\\"message\\\": \\\"Show RSRP trends\\\"}'\",\n",
    "    \"curl -X POST 'http://localhost:8000/anomaly-detection' -d '{\\\"kpi_name\\\": \\\"RSRP\\\"}'\",\n",
    "    \"curl -X POST 'http://localhost:8000/upload-data' -F 'file=@data.csv'\",\n",
    "    \"curl -X GET 'http://localhost:8000/status'\"\n",
    "]\n",
    "\n",
    "for example in api_examples:\n",
    "    print(f\"  {example}\")\n",
    "\n",
    "print(\"\\n To start the server:\")\n",
    "print(\"  python -m telecom_ai_platform.main server --port 8000\")\n",
    "print(\"  Then visit: http://localhost:8000/docs for interactive API documentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd4604",
   "metadata": {},
   "source": [
    "## Complete Workflow Example\n",
    "\n",
    "Let's demonstrate a complete end-to-end workflow using the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ea2e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Workflow Demonstration\n",
      "====================================\n",
      "\n",
      "Step 1: Initialize Platform\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:13:51 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:13:51 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:13:51 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:13:51 - TelecomConversationalAgent - INFO - _initialize_llm:321 - Gemini LLM initialized successfully\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - load_model:386 - Model loaded from c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - TelecomAPIServer - WARNING - _load_models:150 - Could not load models: Error(s) in loading state_dict for AutoEncoder:\n",
      "\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([8, 9]) from checkpoint, the shape in current model is torch.Size([16, 9]).\n",
      "\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([4, 8]) from checkpoint, the shape in current model is torch.Size([8, 16]).\n",
      "\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([8, 4]) from checkpoint, the shape in current model is torch.Size([16, 8]).\n",
      "\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([9, 8]) from checkpoint, the shape in current model is torch.Size([9, 16]).\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - load_model:386 - Model loaded from c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - TelecomAPIServer - WARNING - _load_models:150 - Could not load models: Error(s) in loading state_dict for AutoEncoder:\n",
      "\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([8, 9]) from checkpoint, the shape in current model is torch.Size([16, 9]).\n",
      "\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for encoder.2.weight: copying a param with shape torch.Size([4, 8]) from checkpoint, the shape in current model is torch.Size([8, 16]).\n",
      "\tsize mismatch for encoder.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([8, 4]) from checkpoint, the shape in current model is torch.Size([16, 8]).\n",
      "\tsize mismatch for decoder.0.bias: copying a param with shape torch.Size([8]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for decoder.2.weight: copying a param with shape torch.Size([9, 8]) from checkpoint, the shape in current model is torch.Size([9, 16]).\n",
      "2025-08-06 13:13:51 - TelecomAIPlatform - INFO - __init__:44 - Telecom AI Platform initialized successfully\n",
      "Platform initialized\n",
      "\n",
      "Step 2: Use Already Processed Data\n",
      "Using processed dataset: 21,060 records\n",
      "\n",
      "Step 3: Train Anomaly Detection Models\n",
      "2025-08-06 13:13:51 - ModelTrainer - INFO - train_anomaly_detector:291 - Starting anomaly detector training\n",
      "2025-08-06 13:13:51 - TelecomAIPlatform - INFO - __init__:44 - Telecom AI Platform initialized successfully\n",
      "Platform initialized\n",
      "\n",
      "Step 2: Use Already Processed Data\n",
      "Using processed dataset: 21,060 records\n",
      "\n",
      "Step 3: Train Anomaly Detection Models\n",
      "2025-08-06 13:13:51 - ModelTrainer - INFO - train_anomaly_detector:291 - Starting anomaly detector training\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - __init__:408 - Initialized KPIAnomalyDetector on cuda\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:421 - Starting training for all KPI detectors\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RSRP\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:421 - Starting training for all KPI detectors\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RSRP\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RSRP on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:207 - Training completed for RSRP\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for SINR\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training autoencoder on 21060 samples\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:207 - Training completed for RSRP\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for SINR\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized autoencoder detector for SINR on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training autoencoder on 21060 samples\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:207 - Training completed for SINR\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for DL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for DL_Throughput on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:207 - Training completed for SINR\n",
      "2025-08-06 13:13:51 - KPIAnomalyDetector - INFO - fit:426 - Training detector for DL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for DL_Throughput on cuda\n",
      "2025-08-06 13:13:51 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:207 - Training completed for DL_Throughput\n",
      "2025-08-06 13:13:52 - KPIAnomalyDetector - INFO - fit:426 - Training detector for UL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for UL_Throughput on cuda\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:207 - Training completed for DL_Throughput\n",
      "2025-08-06 13:13:52 - KPIAnomalyDetector - INFO - fit:426 - Training detector for UL_Throughput\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for UL_Throughput on cuda\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:207 - Training completed for UL_Throughput\n",
      "2025-08-06 13:13:52 - KPIAnomalyDetector - INFO - fit:426 - Training detector for CPU_Utilization\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for CPU_Utilization on cuda\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:207 - Training completed for UL_Throughput\n",
      "2025-08-06 13:13:52 - KPIAnomalyDetector - INFO - fit:426 - Training detector for CPU_Utilization\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for CPU_Utilization on cuda\n",
      "2025-08-06 13:13:52 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for CPU_Utilization\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Active_Users\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Active_Users on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for CPU_Utilization\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Active_Users\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Active_Users on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for Active_Users\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RTT\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RTT on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for Active_Users\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for RTT\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized isolation_forest detector for RTT on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training isolation_forest on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for RTT\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Packet_Loss\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Packet_Loss on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:207 - Training completed for RTT\n",
      "2025-08-06 13:13:54 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Packet_Loss\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Packet_Loss on cuda\n",
      "2025-08-06 13:13:54 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - fit:207 - Training completed for Packet_Loss\n",
      "2025-08-06 13:13:56 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Call_Drop_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Call_Drop_Rate on cuda\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - fit:207 - Training completed for Packet_Loss\n",
      "2025-08-06 13:13:56 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Call_Drop_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - __init__:154 - Initialized one_class_svm detector for Call_Drop_Rate on cuda\n",
      "2025-08-06 13:13:56 - KPISpecificDetector - INFO - fit:190 - Training one_class_svm on 21060 samples\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - fit:207 - Training completed for Call_Drop_Rate\n",
      "2025-08-06 13:13:57 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Handover_Success_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Handover_Success_Rate on cuda\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - fit:207 - Training completed for Call_Drop_Rate\n",
      "2025-08-06 13:13:57 - KPIAnomalyDetector - INFO - fit:426 - Training detector for Handover_Success_Rate\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - __init__:154 - Initialized gaussian_mixture detector for Handover_Success_Rate on cuda\n",
      "2025-08-06 13:13:57 - KPISpecificDetector - INFO - fit:190 - Training gaussian_mixture on 21060 samples\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - fit:207 - Training completed for Handover_Success_Rate\n",
      "2025-08-06 13:13:58 - KPIAnomalyDetector - INFO - fit:441 - Training completed for 10 KPI detectors\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\SINR_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\DL_Throughput_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - fit:207 - Training completed for Handover_Success_Rate\n",
      "2025-08-06 13:13:58 - KPIAnomalyDetector - INFO - fit:441 - Training completed for 10 KPI detectors\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RSRP_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\SINR_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\DL_Throughput_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\UL_Throughput_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\CPU_Utilization_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Active_Users_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RTT_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Packet_Loss_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Call_Drop_Rate_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Handover_Success_Rate_detector.pkl\n",
      "2025-08-06 13:13:58 - KPIAnomalyDetector - INFO - save_all_models:554 - All models saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\n",
      "2025-08-06 13:13:58 - ModelTrainer - INFO - train_anomaly_detector:308 - Model saved successfully\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\UL_Throughput_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\CPU_Utilization_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Active_Users_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\RTT_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Packet_Loss_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Call_Drop_Rate_detector.pkl\n",
      "2025-08-06 13:13:58 - KPISpecificDetector - INFO - save_model:362 - Model saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\\Handover_Success_Rate_detector.pkl\n",
      "2025-08-06 13:13:58 - KPIAnomalyDetector - INFO - save_all_models:554 - All models saved to c:\\Users\\jcati\\Desktop\\Chinmay\\Extras\\AIRA-ASSESMENT\\telecom_ai_platform\\models\n",
      "2025-08-06 13:13:58 - ModelTrainer - INFO - train_anomaly_detector:308 - Model saved successfully\n",
      "Models trained successfully\n",
      "\n",
      "Step 4: Detect Anomalies\n",
      "Models trained successfully\n",
      "\n",
      "Step 4: Detect Anomalies\n",
      "2025-08-06 13:14:11 - KPIAnomalyDetector - INFO - detect_anomalies:514 - Detected 7380 anomalies out of 210600 samples\n",
      "2025-08-06 13:14:11 - KPIAnomalyDetector - INFO - detect_anomalies:514 - Detected 7380 anomalies out of 210600 samples\n",
      "Detected 7380 anomalies\n",
      "\n",
      "Step 5: Generate Insights\n",
      "Detected 7380 anomalies\n",
      "\n",
      "Step 5: Generate Insights\n",
      "Generated comprehensive analysis report\n",
      "\n",
      "Step 6: Final Results Summary\n",
      "  Total Records Analyzed: 21,060\n",
      "  Anomalies Detected: 7,380\n",
      "  Anomaly Rate: 35.04%\n",
      "  Sites Analyzed: 100\n",
      "  KPIs Monitored: 10\n",
      "\n",
      "Severity Breakdown:\n",
      "    Low: 4,214\n",
      "    Medium: 1\n",
      "    High: 3,165\n",
      "\n",
      "Workflow completed successfully!\n",
      "The platform is ready for production use.\n",
      "\n",
      "==================================================\n",
      "ALTERNATIVE: Full Pipeline Processing from File\n",
      "==================================================\n",
      "If you want to demonstrate the complete pipeline from raw data:\n",
      "1. workflow_data = workflow_platform.trainer.data_processor.process_pipeline('../../AD_data_10KPI.csv')\n",
      "2. This would load, clean, engineer features, and scale the raw data\n",
      "3. Then proceed with training and anomaly detection as shown above\n",
      "Generated comprehensive analysis report\n",
      "\n",
      "Step 6: Final Results Summary\n",
      "  Total Records Analyzed: 21,060\n",
      "  Anomalies Detected: 7,380\n",
      "  Anomaly Rate: 35.04%\n",
      "  Sites Analyzed: 100\n",
      "  KPIs Monitored: 10\n",
      "\n",
      "Severity Breakdown:\n",
      "    Low: 4,214\n",
      "    Medium: 1\n",
      "    High: 3,165\n",
      "\n",
      "Workflow completed successfully!\n",
      "The platform is ready for production use.\n",
      "\n",
      "==================================================\n",
      "ALTERNATIVE: Full Pipeline Processing from File\n",
      "==================================================\n",
      "If you want to demonstrate the complete pipeline from raw data:\n",
      "1. workflow_data = workflow_platform.trainer.data_processor.process_pipeline('../../AD_data_10KPI.csv')\n",
      "2. This would load, clean, engineer features, and scale the raw data\n",
      "3. Then proceed with training and anomaly detection as shown above\n"
     ]
    }
   ],
   "source": [
    "print(\"Complete Workflow Demonstration\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# Step 1: Initialize Platform\n",
    "print(\"Step 1: Initialize Platform\")\n",
    "workflow_platform = TelecomAIPlatform()\n",
    "print(\"Platform initialized\\n\")\n",
    "\n",
    "# Step 2: Use Already Processed Data\n",
    "print(\"Step 2: Use Already Processed Data\")\n",
    "# Since we already have processed data from previous steps, we'll use that\n",
    "# instead of reprocessing through the pipeline\n",
    "workflow_data = processed_data.copy()\n",
    "print(f\"Using processed dataset: {len(workflow_data):,} records\\n\")\n",
    "\n",
    "# Step 3: Train Models\n",
    "print(\"Step 3: Train Anomaly Detection Models\")\n",
    "workflow_detector = workflow_platform.trainer.train_anomaly_detector(workflow_data)\n",
    "print(\"Models trained successfully\\n\")\n",
    "\n",
    "# Step 4: Detect Anomalies\n",
    "print(\"Step 4: Detect Anomalies\")\n",
    "workflow_anomalies = workflow_detector.detect_anomalies(workflow_data)\n",
    "workflow_anomaly_count = sum(1 for a in workflow_anomalies if a.is_anomaly)\n",
    "print(f\"Detected {workflow_anomaly_count} anomalies\\n\")\n",
    "\n",
    "# Step 5: Generate Insights\n",
    "print(\"Step 5: Generate Insights\")\n",
    "workflow_visualizer = TelecomVisualizer(workflow_platform.config)\n",
    "workflow_summary = workflow_visualizer.generate_summary_report(workflow_data, workflow_anomalies)\n",
    "print(f\"Generated comprehensive analysis report\\n\")\n",
    "\n",
    "# Step 6: Display Results\n",
    "print(\"Step 6: Final Results Summary\")\n",
    "print(f\"  Total Records Analyzed: {len(workflow_data):,}\")\n",
    "print(f\"  Anomalies Detected: {workflow_anomaly_count:,}\")\n",
    "print(f\"  Anomaly Rate: {workflow_anomaly_count/len(workflow_data):.2%}\")\n",
    "print(f\"  Sites Analyzed: {workflow_data['Site_ID'].nunique()}\")\n",
    "print(f\"  KPIs Monitored: {len([col for col in workflow_platform.config.data.kpi_columns if col in workflow_data.columns])}\")\n",
    "\n",
    "# Show severity breakdown\n",
    "severity_breakdown = {}\n",
    "for severity in ['low', 'medium', 'high']:\n",
    "    count = sum(1 for a in workflow_anomalies if a.is_anomaly and a.severity == severity)\n",
    "    severity_breakdown[severity] = count\n",
    "\n",
    "print(f\"\\nSeverity Breakdown:\")\n",
    "for severity, count in severity_breakdown.items():\n",
    "    print(f\"    {severity.capitalize()}: {count:,}\")\n",
    "\n",
    "print(\"\\nWorkflow completed successfully!\")\n",
    "print(\"The platform is ready for production use.\")\n",
    "\n",
    "# Optional: Demonstrate full pipeline processing with file path\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ALTERNATIVE: Full Pipeline Processing from File\")\n",
    "print(\"=\"*50)\n",
    "print(\"If you want to demonstrate the complete pipeline from raw data:\")\n",
    "print(f\"1. workflow_data = workflow_platform.trainer.data_processor.process_pipeline('{data_path}')\")\n",
    "print(\"2. This would load, clean, engineer features, and scale the raw data\")\n",
    "print(\"3. Then proceed with training and anomaly detection as shown above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telecom-kpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
